{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "451bc6b0-8926-47dd-aa52-22749c5eeeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import natsort\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from squeakout import SqueakOut_autoencoder as SqueakOut\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9aba9b2-ac30-40a2-a0d6-837fe942119a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataSet(Dataset):\n",
    "    def __init__(self, main_dir, transform):\n",
    "        self.main_dir = main_dir\n",
    "        self.transform = transform\n",
    "        all_imgs = os.listdir(main_dir)\n",
    "        self.total_imgs = natsort.natsorted(all_imgs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.total_imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_loc = os.path.join(self.main_dir, self.total_imgs[idx])\n",
    "        image = Image.open(img_loc).convert(\"L\").resize((512, 512), Image.ANTIALIAS)\n",
    "        tensor_image = self.transform(image)\n",
    "        return tensor_image\n",
    "    \n",
    "transToTensor = transforms.Compose([transforms.Resize((512, 512)), transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f413113-079b-4b48-8972-d1d12beec4cb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 18.029MB\n",
      "Number of trainable parameters: 4683600\n"
     ]
    }
   ],
   "source": [
    "model = SqueakOut()\n",
    "ckpt_path = \"./squeakout_weights.ckpt\"\n",
    "checkpoint = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "\n",
    "param_size = 0\n",
    "for param in model.parameters():\n",
    "    param_size += param.nelement() * param.element_size()\n",
    "buffer_size = 0\n",
    "for buffer in model.buffers():\n",
    "    buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "print('model size: {:.3f}MB'.format(size_all_mb))\n",
    "\n",
    "\n",
    "num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Number of trainable parameters: {num_trainable_params}\")\n",
    "\n",
    "\n",
    "# move to GPU!\n",
    "if torch.cuda.is_available(): model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0403321-c721-4902-8f3c-34b6579aa7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path where source spectrogram directories are located\n",
    "src_data = \"./dataset/test/\"\n",
    "\n",
    "# path where segmentation masks will be saved\n",
    "# (will follow same structure as source data)\n",
    "save_root = \"./outputs/segmentation/\"\n",
    "\n",
    "# path to save a montage showing the original spectrogram,\n",
    "# the segmentation mask, and an overlay of the spectrogram\n",
    "# with mask for visualization purposes\n",
    "montage_root = \"./outputs/montages/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc30ba8-ff76-4dab-a82a-9a4d54fc7c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ./images/\n",
      "number of spectrograms 849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/gibbs/project/dietrich/gms58/conda_envs/segm/lib/python3.7/site-packages/ipykernel_launcher.py:13: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  del sys.path[0]\n",
      "/gpfs/gibbs/project/dietrich/gms58/conda_envs/segm/lib/python3.7/site-packages/ipykernel_launcher.py:13: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  del sys.path[0]\n",
      "/gpfs/gibbs/project/dietrich/gms58/conda_envs/segm/lib/python3.7/site-packages/ipykernel_launcher.py:13: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  del sys.path[0]\n",
      "/gpfs/gibbs/project/dietrich/gms58/conda_envs/segm/lib/python3.7/site-packages/ipykernel_launcher.py:13: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  del sys.path[0]\n",
      "/gpfs/gibbs/project/dietrich/gms58/conda_envs/segm/lib/python3.7/site-packages/ipykernel_launcher.py:31: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/gpfs/gibbs/project/dietrich/gms58/conda_envs/segm/lib/python3.7/site-packages/ipykernel_launcher.py:32: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/gpfs/gibbs/project/dietrich/gms58/conda_envs/segm/lib/python3.7/site-packages/ipykernel_launcher.py:38: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    }
   ],
   "source": [
    "# for each recording directory:\n",
    "#     open all spectrograms as a dataset\n",
    "#     pass the dataset to the neural network and save segmentation masks\n",
    "\n",
    "for enum, data_dir in enumerate([src_data]):\n",
    "    print(f\"running {data_dir}\")\n",
    "    out_dir_group = os.path.dirname(data_dir).split('/')[-1]\n",
    "    \n",
    "    # create directories to save masks and montage\n",
    "    segm_out_dir = os.path.join(save_root, out_dir_group)\n",
    "    if not os.path.exists(segm_out_dir):\n",
    "        os.makedirs(segm_out_dir)\n",
    "    mont_out_dir = os.path.join(montage_root, out_dir_group)\n",
    "    if not os.path.exists(mont_out_dir):\n",
    "        os.makedirs(mont_out_dir)\n",
    "\n",
    "    # create spectrogram dataset\n",
    "    my_dataset = CustomDataSet(data_dir, transform=transToTensor)\n",
    "    print(f\"number of spectrograms {my_dataset.__len__()}\")\n",
    "    train_loader = data.DataLoader(my_dataset, batch_size=8, shuffle=False, num_workers=4, drop_last=False)\n",
    "    segmentations = []\n",
    "    spectrograms = []\n",
    "    \n",
    "    # iterate over batches and get masks\n",
    "    for idx, img in enumerate(train_loader):\n",
    "        out = model(img.to(\"cuda\"))\n",
    "        segmentations.append(out.detach())\n",
    "        spectrograms.append(img)\n",
    "\n",
    "\n",
    "    segm = np.asarray([x.cpu().numpy() for x in segmentations])\n",
    "    spec = np.asarray([x.cpu().numpy() for x in spectrograms])\n",
    "\n",
    "    __, __, spec_w, spec_h = spec[0].shape\n",
    "    a=0\n",
    "    for imid, im in enumerate(segm):\n",
    "        for nimid, nim in enumerate(im):\n",
    "            spc = (spec[imid][nimid][0] * 255).astype(np.int)\n",
    "            mask = (torch.sigmoid(torch.tensor(nim[0])).detach().numpy() > 0.51) * 255\n",
    "            mask_img = Image.fromarray(mask.astype(\"uint8\"))\n",
    "            mask_output_path = os.path.join(segm_out_dir, my_dataset.total_imgs[a])\n",
    "            mask_img.convert(\"L\").save(mask_output_path)\n",
    "\n",
    "            img = np.hstack([spc, mask, spc* 0.5 + 0.5 * mask])\n",
    "            img = Image.fromarray(img)\n",
    "            img_output_path = os.path.join(mont_out_dir, my_dataset.total_imgs[a][:-4] + \"_montage.png\")\n",
    "            img.convert(\"L\").save(img_output_path)\n",
    "            a+=1\n",
    "\n",
    "    print(f\"{a} masks saved\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492388d3-6fef-4a60-b161-9bc84df7ed75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31449e7d-1d4b-42f3-a6a1-81fb0a0aa1eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20257563-2e7c-4462-800c-a048a9ce67c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bef455-db44-42fd-8de1-f40d9bb7776e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c880b6d-fe6c-48f2-a17a-a43c3fd41035",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
